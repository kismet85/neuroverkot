{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ladataan englanti-suomi lauseparit tiedostosta\n",
    "# Lisätään [start] ja [end] -tokenit dekooderin harjoittelua varten"
   ],
   "id": "d9b752a3a67500d8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-25T06:26:21.092124Z",
     "start_time": "2025-04-25T06:26:20.941121Z"
    }
   },
   "source": [
    "text_file = \"fin-eng/fin.txt\"\n",
    "\n",
    "with open(text_file, encoding='utf-8') as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    english, finnish, _ = line.split(\"\\t\")\n",
    "    finnish = \"[start] \" + finnish + \" [end]\"\n",
    "    text_pairs.append((english, finnish))\n"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tuodaan tarvittavat kirjastot ja sekoitetaan lauseet\n",
    "# Jaetaan 85 % koulutusdataan ja 15 % validointiin\n",
    "# Erotellaan lähdekieli (englanti) ja kohdekieli (suomi)\n",
    "# TextVectorization muuntaa tekstin kokonaislukujonoiksi.\n",
    "# Mahdollistaa sanojen syöttämisen neuroverkkomalliin.\n",
    "# Käytetään 15 000 sanaa ja maksimipituus 40 sanaa"
   ],
   "id": "e28b7bef97486f6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:26:21.565198Z",
     "start_time": "2025-04-25T06:26:21.098680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "train_pairs = text_pairs[:-num_val_samples]\n",
    "val_pairs = text_pairs[-num_val_samples:]\n",
    "\n",
    "source_texts = [pair[0] for pair in train_pairs]\n",
    "target_texts = [pair[1] for pair in train_pairs]\n",
    "\n",
    "source_vectorization = TextVectorization(max_tokens=15000, output_mode=\"int\", output_sequence_length=40)\n",
    "target_vectorization = TextVectorization(max_tokens=15000, output_mode=\"int\", output_sequence_length=40)\n",
    "\n",
    "source_vectorization.adapt(source_texts)\n",
    "target_vectorization.adapt(target_texts)"
   ],
   "id": "e958766fd91b671e",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Muotoillaan data Transformer-mallia varten.\n",
    "# Palauttaa syötteet kooderille ja dekooderille + oikeat vastaukset.\n",
    "# Tehdään TensorFlow-datasetit harjoitteluun ja validointiin.\n"
   ],
   "id": "e52bc6d5110eacb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:26:21.929996Z",
     "start_time": "2025-04-25T06:26:21.574837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_dataset(src, tgt):\n",
    "    src = source_vectorization(src)\n",
    "    tgt = target_vectorization(tgt)\n",
    "    return ({\"encoder_inputs\": src, \"decoder_inputs\": tgt[:, :-1]}, tgt[:, 1:])\n",
    "\n",
    "batch_size = 64\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((source_texts, target_texts))\n",
    "train_ds = train_ds.batch(batch_size).map(format_dataset).prefetch(1)\n",
    "\n",
    "val_source_texts = [pair[0] for pair in val_pairs]\n",
    "val_target_texts = [pair[1] for pair in val_pairs]\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_source_texts, val_target_texts))\n",
    "val_ds = val_ds.batch(batch_size).map(format_dataset).prefetch(1)"
   ],
   "id": "24b8d9bef4595e29",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PositionalEmbedding lisää sanojen järjestystiedon mallille.\n",
    "# Transformer tarvitsee tämän ymmärtääkseen sanojen sijainnin lauseessa.\n"
   ],
   "id": "49bdc244917b3aed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:26:21.946084Z",
     "start_time": "2025-04-25T06:26:21.940166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=embed_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return keras.ops.not_equal(inputs, 0)\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "        })\n",
    "        return config"
   ],
   "id": "21b0351006d7d8a",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# TransformerEncoder hyödyntää monipäistä huomiomekanismia ja tiheää verkkoa.\n",
    "# Koodaa syötelauseen numeeriseksi esitykseksi.\n"
   ],
   "id": "837a63dcea258789"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:26:21.962915Z",
     "start_time": "2025-04-25T06:26:21.956674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential([\n",
    "            layers.Dense(dense_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "        else:\n",
    "            padding_mask = None\n",
    "\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.attention.key_dim,\n",
    "            \"dense_dim\": self.dense_proj.layers[0].units,\n",
    "            \"num_heads\": self.attention.num_heads,\n",
    "        })\n",
    "        return config"
   ],
   "id": "bb5bd4f21acdff6b",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# TransformerDecoder käyttää myös monipäistä huomiota ja kausaalimaskia.\n",
    "# Mahdollistaa sanan ennustamisen yksi kerrallaan ilman tulevien sanojen näkemistä.\n"
   ],
   "id": "7cfb06635f2b5731"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:26:21.980568Z",
     "start_time": "2025-04-25T06:26:21.972525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention_1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential([\n",
    "            layers.Dense(latent_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "        else:\n",
    "            padding_mask = None\n",
    "\n",
    "        attention_output_1 = self.attention_1(inputs, inputs, attention_mask=causal_mask)\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(out_1, encoder_outputs, attention_mask=padding_mask)\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, seq_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(seq_length)[:, tf.newaxis]\n",
    "        j = tf.range(seq_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        return tf.reshape(mask, (1, seq_length, seq_length))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.attention_1.key_dim,\n",
    "            \"latent_dim\": self.dense_proj.layers[0].units,\n",
    "            \"num_heads\": self.attention_1.num_heads,\n",
    "        })\n",
    "        return config\n"
   ],
   "id": "50ac2838b03351e0",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Rakennetaan koko malli: syöte kooderille → tulos dekooderille.\n",
    "# Lopputulos on sanan todennäköisyysjakauma seuraavaksi sanaksi.\n",
    "# Käytetään sparse_categorical_crossentropy -häviötä koska vastaukset ovat kokonaislukuja.\n"
   ],
   "id": "8ec077ab13ea8fed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:26:22.420715Z",
     "start_time": "2025-04-25T06:26:21.989923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embed_dim = 256\n",
    "dense_dim = 1024\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(40, 15000, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "x = PositionalEmbedding(40, 15000, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "decoder_outputs = layers.Dense(15000, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ],
   "id": "b9d512fbe00e6da9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_5\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m) │  \u001B[38;5;34m3,850,240\u001B[0m │ encoder_inputs[\u001B[38;5;34m0\u001B[0m… │\n",
       "│ (\u001B[38;5;33mPositionalEmbeddi…\u001B[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ encoder_inputs[\u001B[38;5;34m0\u001B[0m… │\n",
       "│ (\u001B[38;5;33mNotEqual\u001B[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m) │  \u001B[38;5;34m3,850,240\u001B[0m │ decoder_inputs[\u001B[38;5;34m0\u001B[0m… │\n",
       "│ (\u001B[38;5;33mPositionalEmbeddi…\u001B[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m) │  \u001B[38;5;34m2,630,144\u001B[0m │ positional_embed… │\n",
       "│ (\u001B[38;5;33mTransformerEncode…\u001B[0m │                   │            │ not_equal_2[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decode… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m) │  \u001B[38;5;34m4,734,208\u001B[0m │ positional_embed… │\n",
       "│ (\u001B[38;5;33mTransformerDecode…\u001B[0m │                   │            │ transformer_enco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m,      │  \u001B[38;5;34m3,855,000\u001B[0m │ transformer_deco… │\n",
       "│                     │ \u001B[38;5;34m15000\u001B[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,850,240</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,850,240</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,630,144</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,734,208</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855,000</span> │ transformer_deco… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m18,919,832\u001B[0m (72.17 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,919,832</span> (72.17 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m18,919,832\u001B[0m (72.17 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,919,832</span> (72.17 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Harjoitetaan mallia 3 epochin ajan.\n",
    "# Tämä riittää osoittamaan, että malli oppii – tehtävä ei vaadi täydellistä käännöstä.\n",
    "# Arvioidaan malli harjoitusdatalla.\n",
    "# Antaa käsityksen siitä, kuinka hyvin malli oppi.\n"
   ],
   "id": "f7ea3331ef4a34cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T07:16:40.371833Z",
     "start_time": "2025-04-25T06:26:22.437680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = model.fit(train_ds, epochs=3, validation_data=val_ds)\n",
    "\n",
    "model.evaluate(train_ds)"
   ],
   "id": "866b6eacf75b7388",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001B[1m960/960\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m931s\u001B[0m 965ms/step - accuracy: 0.0756 - loss: 4.6717 - val_accuracy: 0.0944 - val_loss: 2.8368\n",
      "Epoch 2/3\n",
      "\u001B[1m960/960\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m922s\u001B[0m 961ms/step - accuracy: 0.0985 - loss: 2.6848 - val_accuracy: 0.1039 - val_loss: 2.2489\n",
      "Epoch 3/3\n",
      "\u001B[1m960/960\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m915s\u001B[0m 953ms/step - accuracy: 0.1086 - loss: 2.0269 - val_accuracy: 0.1059 - val_loss: 2.1272\n",
      "\u001B[1m960/960\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m251s\u001B[0m 261ms/step - accuracy: 0.1127 - loss: 1.7775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.653383493423462, 0.11564385890960693]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tämä funktio tekee käännöksen annetusta englanninkielisestä lauseesta suomeksi.\n",
    "# Ennustaa seuraavan sanan yksi kerrallaan, kunnes pääsee [end]-tokeniin.\n",
    "# Testataan mallia yhdellä esimerkkilauseella.\n",
    "# Tulostetaan mallin tuottama suomennos.\n"
   ],
   "id": "e858efa9f0406fd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T07:16:44.934197Z",
     "start_time": "2025-04-25T07:16:40.549876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for _ in range(40):\n",
    "        tokenized_target = target_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = model.predict({\"encoder_inputs\": tokenized_input, \"decoder_inputs\": tokenized_target}, verbose=0)\n",
    "        sampled_token_index = np.argmax(predictions[0, -1, :])\n",
    "        sampled_token = target_vectorization.get_vocabulary()[sampled_token_index]\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "    return decoded_sentence\n",
    "\n",
    "# Test\n",
    "print(decode_sequence(\"I am hungry.\"))\n"
   ],
   "id": "d169bce42aa78adc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[start] end end end end end minulla minulla minulla minulla minulla nälkä nälkä end nälkä minulla nälkä nälkä nälkä end nälkä nälkä end nälkä minulla nälkä nälkä end nälkä nälkä on nälkä end nälkä nälkä end nälkä nälkä on nälkä nälkä\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T07:16:44.942895Z",
     "start_time": "2025-04-25T07:16:44.940460Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "133be1cd580f4ad",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
